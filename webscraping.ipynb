{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/28/2020\n"
     ]
    }
   ],
   "source": [
    "#Use beautiful soup to retrive all MTA files from website (web scrape) just for 2020-01-01 to most recent\n",
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'http://web.mta.info/developers/turnstile.html'\n",
    "\n",
    "#https://blog.proxypage.io/web-scrape-using-python-in-less-than-5-minutes-2/\n",
    "#https://hackersandslackers.com/scraping-urls-with-beautifulsoup/\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#print(soup.prettify()) you can see 'soup' is our entire html page\n",
    "\n",
    "URL_PREFACE = 'http://web.mta.info/developers/'\n",
    "a = soup.find_all('a')\n",
    "o = ()\n",
    "for i in range(37,42):\n",
    "#for i in range(37, len(a)):\n",
    "    ins = (a[i].get_text(), URL_PREFACE + a[i]['href'],)\n",
    "    o = o + (ins,)\n",
    "\n",
    "col = ['C/A','UNIT','SCP','STATION','LINENAME','DIVISION','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for a, b in o:\n",
    "    d = a[-4:]\n",
    "    if d.find('2020') !=-1:\n",
    "        df = pd.read_csv(b,  sep=r'\\s*,\\s*', header=0, engine='python') #else \"EXITS\" gives an error, python engine will avoid warning\n",
    "        df['dt'] = df['DATE'] + ' ' + df['TIME']\n",
    "        data = pd.concat([data, df])\n",
    "\n",
    "print(data.DATE.min())        \n",
    "\n",
    "data['entry_per_hour'] = data.ENTRIES - data.ENTRIES.shift(1)\n",
    "#df['hourly_entry'] = hourly_entry.fillna(0)\n",
    "\n",
    "data['exit_per_hour'] = data.EXITS - data.EXITS.shift(1)\n",
    "#df['hourly_exit'] = hourly_exit.fillna(0)\n",
    "\n",
    "data['use_per_hour'] = data.entry_per_hour + data.exit_per_hour\n",
    "\n",
    "data['day'] = pd.to_datetime(data['dt']).dt.day_name()\n",
    "\n",
    "data['hour'] = (pd.to_datetime(data['dt'])).dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning data for extreme values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evidence of extremity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#some graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point is: anything above __x__ is unrealistic, so we will ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non-negative and LESS THAN 100000?\n",
    "# clean 'HOURLY_ENTRIES'\n",
    "#mask = data.entry_per_hour.astype(int) <= 20000\n",
    "#data = data.loc(mask)\n",
    "\n",
    "data['entry_per_hour'] = data.entry_per_hour.transform(\n",
    "        lambda x: np.where((x<0)|(x>20000),x.mask((x<0)|(x>20000)).mean(),x))\n",
    "    \n",
    "# clean 'HOURLY_EXITS'\n",
    "data['exit_per_hour'] = data.exit_per_hour.transform(\n",
    "        lambda x: np.where((x<0)|(x>20000),x.mask((x<0)|(x>20000)).mean(),x))\n",
    "\n",
    "\n",
    "data['use_per_hour'] = data.entry_per_hour + data.exit_per_hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof that outliers are gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What graph can we show?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def check_weekend(day):\n",
    "    weekno = datetime.datetime.today().weekday()\n",
    "\n",
    "    if weekno < 5:\n",
    "        return False\n",
    "    else:  # 5 Sat, 6 Sun\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    }
   ],
   "source": [
    "data.groupby(data['STATION']).sum()['use_per_hour']\n",
    "stations = data['STATION'].unique()\n",
    "print(len(stations))\n",
    "\n",
    "\n",
    "\n",
    "days = data['day'].unique()\n",
    "#data['weekend'] = check_weekend(data['day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION\n",
       "34 ST-PENN STA     1.938145e+06\n",
       "34 ST-HERALD SQ    1.537924e+06\n",
       "GRD CNTRL-42 ST    1.443054e+06\n",
       "86 ST              1.421662e+06\n",
       "125 ST             1.335138e+06\n",
       "42 ST-PORT AUTH    1.226611e+06\n",
       "14 ST-UNION SQ     1.201797e+06\n",
       "23 ST              1.138865e+06\n",
       "59 ST              1.113387e+06\n",
       "FLUSHING-MAIN      1.045703e+06\n",
       "Name: use_per_hour, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "#data.groupby('DATE')['entry_per_hour','exit_per_hour'].sum().round(2).rename(\n",
    "#    columns = {'DATE': \"DATE\", 'entry_per_hour': \"TOTAL_ENTRIES\",'exit_per_hour': 'TOTAL_EXITS'}).unstack().plot(ax=ax)\n",
    "\n",
    "\n",
    "data = data.groupby('STATION')['use_per_hour'].sum().sort_values(ascending =False)\n",
    "data.head(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
